# 爬虫

## 一.安装库
> pip3 install requests
>> 我的电脑上安装了python27和36，所以pip3对应的是python3。如果只有一个，就pip install requests即可
### 1. 使用
```python
import requests
res = requests.get(url)

res.content # 获取到二进制流
res.text # 获取到内容
```
### 2. 查看网站爬虫协议
> 例：'https://www.baidu.com/robots.txt'

## 二. 常用属性
> 例如 print(res.status_code) # 200 <br />
> res.encoding = 'utf-8
<image-preview imgUrl="python/requests1.png" width='200'></image-preview>

## 三. 解析数据
> 1. 手动安装
>> pip3 install bs4
> 2. 解析数据用，即将爬取的内容转换成bs对象
### 1. bs对象
```python
import requests
from bs4 import BeautifulSoup

res = requests.get('http://xxxxxxx/index.html')
html = res.text
# 两个参数： 第一个必须为字符串类型；第二个是解析器，有多种可选
soup = BeautifulSoup(html, 'html.parser')
```
### 2. 查找内容
> 承接上文
```py
# find fing_all select
soup.find('div') # 查找第一个div 'bs4.element.Tag'
result = soup.find_all('div') # 查找出所有的div 'bs4.element.ResultSet'

# class和类冲突，所有改成class_。
soup.find('div', class_='show-list-item')

# find_all返回的结构均为 []
for i in result:
    print(i)
```
<image-preview imgUrl="python/find.png" width='200'></image-preview>

### 3. tag对象
> find查找的结果是tag对象
> result.find(class_='xxxx') # None, 因为div下面没有tag了。只有text内容
>> 即result: \<div class='xxxx'> 123456 <\/div>
>> result.text # 123456 <br />

> 又比如 a： \<a href='https://xxxxxx'><\/a>
>> a['href] # https://xxxxxx

<image-preview imgUrl="python/tag.png" width='200'></image-preview>

### 4. 实践操作
```py
# 豆瓣电影排名： 名称 + 评分
import requests
from bs4 import BeautifulSoup

headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36'}
res = requests.get('https://movie.douban.com/chart', headers=headers)
html = res.text

soup = BeautifulSoup(html, 'html.parser')
cont = soup.find_all('div', class_='pl2')

for item in cont:
    name = item.find('div', class_='clearfix').text.replace(' ', '').replace('\n', '')
    a = item.find('a').text.replace(' ', '').replace('\n', '')
    print(a + ' : ' + name)


# 打印效果如下 👇
# 黑寡妇/TheBlackWidow : 6.4(86959人评价)
# 明日之战/幽灵征募/幽灵分遣队 : 6.5(33369人评价)
# 智齿/Limbo : 7.3(9478人评价)
# 杀手妻子的保镖/保镳救杀手2(港)/王牌保镖2 : 6.3(10393人评价)
# 我要我们在一起/10年女友/十年女友 : 6.1(72364人评价)
# 阳光姐妹淘/中国版阳光姐妹淘/SunnySisters : 4.5(32014人评价)
# 六人-泰坦尼克上的中国幸存者/六人/六人：泰坦尼克号上的中国幸存者 : 8.3(16500人评价)
# 宝贝老板2/宝贝老板2：家族企业/宝贝老板：家大业大(台) : 6.6(3867人评价)
# 怪奇宅/採魂邨(港)/怪奇公寓 : 6.9(7206人评价)
# 夏日友晴天/盛夏友晴天(港)/路卡的夏天(台) : 7.3(19038人评价)

```


:::warning 
```py
# 注意文件的名称(json1.py)不能和模块的名称一样 <br />
import json
# str -> json
json.loads(x)
# json -> str
json.dumps(x)
```
:::


### 5. cookie和session
```py
# cookie免登逻辑
import requests
import json

url = 'https://xiaoke.kaikeba.com/example/wordpress/wp-login.php'
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'
}
# 除了log、pwd其他都是默认参数
data = {
    'log': 'kaikeba',
    'pwd': 'kaikeba888',
    'wp-submit': '登录',
    'redirect_to': 'https://xiaoke.kaikeba.com/example/wordpress/2019/10/17/%e5%bc%80%e8%af%be%e5%90%a7%e6%97%a0%e6%95%8c%e5%a5%bd%e5%90%83%e7%9a%84%e9%a3%9f%e5%a0%82%e4%b8%80%e5%91%a8%e8%8f%9c%e8%b0%b1/',
    'testcookie': '1'
}

session = requests.session()
session.post(url, headers=headers, data=data)

# 将生成的cookie转换成 字典
cookie_dict = requests.utils.dict_from_cookiejar(session.cookies)
# 将字典转换成 字符串
cookie_str = json.dumps(cookie_dict)

# 将cookie写入文件存起来
f = open('cookie.txt', 'w')
f.write(cookie_str)

```
```py
# 读取并使用
cookie_txt = open('cookie.txt', 'r')
cookie_dict = json.loads(cookie_txt_read())
cookie = requests.utils.cookiejar_form_dict(cookie_dict)
session.cookies = cookie
```

```py
# try成功就继续往下执行；否则报错FileNotFoundError，走except
try: 
    xxxxxxxxx
except FileNotFoundError: 
    xxxxxxxxx

# to do sometings
```